{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjFSvVqe9U-w"
   },
   "source": [
    "## Face Recognition – Unlock Your Computer With Your Face!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Project Description:\n",
    "\n",
    "In this Project we have followed three steps \n",
    "1.Create traning Data\n",
    "2.Train model\n",
    "3.Run our facial recognition\n",
    "\n",
    "Model is trained on my face so it will detect my face and send me the message on\n",
    "Whatsap,Telegram along with email and sms.\n",
    "\n",
    "For sending the message on whatsap we have used twilio,a third party app which gives us credentials and a number.\n",
    "Same for the sms and for email mailgun has been used, it also provides us the credentials and an email.\n",
    "for telegram we have created a bot on telegram by taking the help of BotFather and created one channel and make \n",
    "our bot and admin of that channel.We will get the message on that channel only.\n",
    "\n",
    "If it will detect someone else face then it will give activate the buzzer and buzz for 5 secs.It is the concept of IoT.\n",
    "It will also require the api key and device id of wifi module.\n",
    "Also it will launch the EC2 instance on the aws cloud and 5gb volume and attach it with the instance.\n",
    "For launching an instance and volume we have used terrform. From one single code everything done in secs.\n",
    "\n",
    "\"\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enTCpPM79U-y"
   },
   "source": [
    "\n",
    "### Step 1 - Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wbnQwrsl9U-z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-1-629aa437f198>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/user/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIvBjd0a9U-1"
   },
   "source": [
    "### Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JnvLgeDN9U-2",
    "outputId": "cbe9827c-5472-49f7-d8a9-f4bbf3546fbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = './faces/user/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model \n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcCFtvQp9U-2"
   },
   "source": [
    "### Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-4-037f57a8c1a6>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making request to Twilio to send a SMS\n",
      "Response received from Twilio is: <Twilio.Api.V2010.MessageInstance account_sid=AC1f9d241e0482ff96339499bd6297b9fc sid=SM1ca27d3b972f4a49a298692b70ca8874>\n",
      "Status of SMS at Twilio is :queued\n",
      "Making request to Mailgun to send an email\n",
      "Response received from Mailgun is: Queued. Thank you.\n",
      "SM6f0c69c9d8ee4fd598185d1a86c158e7\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from boltiot import Email, Sms, Bolt\n",
    "import json, time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from twilio.rest import Client\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "NAME = \"Mahek Batra\"\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "#twilio is used for getting the credentials and number in a free trail account.\n",
    "def sms():\n",
    "    SID = 'AC1f9XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "    AUTH_TOKEN = 'ee3b4c626XXXXXXXXXXXXXXXXXXXXXX'\n",
    "    FROM_NUMBER = +18XXXXXXX\n",
    "    TO_NUMBER =+91937XXXXXXX\n",
    "    \n",
    "    sms = Sms(SID, AUTH_TOKEN, TO_NUMBER, FROM_NUMBER)\n",
    "    \n",
    "    print(\"Making request to Twilio to send a SMS\")\n",
    "    response = sms.send_sms(\"Face detected, This is face of \" + NAME + \" Detected at \" + dt_string)\n",
    "    print(\"Response received from Twilio is: \" + str(response))\n",
    "    print(\"Status of SMS at Twilio is :\" + str(response.status))\n",
    "    \n",
    "\n",
    "#mailgun is used for gettting the credentials and sender's email \n",
    "def mail():\n",
    "    MAILGUN_API_KEY = \"822c6XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "    SANDBOX_URL=  \"sandboxXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" \n",
    "    SENDER_EMAIL = 'Face_Detector@' + SANDBOX_URL\n",
    "    RECIPIENT_EMAIL = \"batraXXXXXXXXXXXXXX\"\n",
    "    \n",
    "    mailer = Email(MAILGUN_API_KEY, SANDBOX_URL, SENDER_EMAIL, RECIPIENT_EMAIL)\n",
    "    \n",
    "    print(\"Making request to Mailgun to send an email\")\n",
    "    response = mailer.send_email(\"Your Face detected\", \"This is face of \" + NAME + \" Detected at \" + dt_string)\n",
    "    response_text = json.loads(response.text)\n",
    "    print(\"Response received from Mailgun is: \" + str(response_text['message']))\n",
    "  \n",
    "    \"\"\"\n",
    "    A Bot is created on telegram wit the help of BotFather and a channel is created and made the bot admin of that\n",
    "    channel and all the messages will get recieved on that channel only.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "def telegram():\n",
    "    telegram_bot_id = \"bot177XXX:XXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "    telegram_chat_id = \"@face_detection_xxxxx\"\n",
    "    \n",
    "    \"\"\"Sends message via Telegram\"\"\"\n",
    "    url = \"https://api.telegram.org/\" + telegram_bot_id + \"/sendMessage\"\n",
    "    telegram_message = \"Face Detected, this is face of \" + NAME + \" Detected at \" + dt_string\n",
    "    data = {\n",
    "        \"chat_id\": telegram_chat_id,\n",
    "        \"text\": telegram_message\n",
    "    }\n",
    "    response = requests.request(\n",
    "        \"POST\",\n",
    "        url,\n",
    "        params=data\n",
    "    )\n",
    "    \n",
    "#Twilio is used for sending the message  \n",
    "def whatsapp():\n",
    "    account_sid = 'AC1fXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' \n",
    "    auth_token = 'ee3b4XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "    client = Client(account_sid, auth_token) \n",
    " \n",
    "    message = client.messages.create( \n",
    "                              from_='whatsapp:+1415XXXXXX', \n",
    "                              body='Face Detected, this is face of '+ NAME + \" Detected at \" + dt_string,      \n",
    "                              to='whatsapp:+91937XXXXXXX'\n",
    "                          ) \n",
    " \n",
    "    print(message.sid)\n",
    "\n",
    "#Terraform is used for creating an instance on the aws cloud and 5gb volume also attach it with the instance\n",
    "def aws():\n",
    "    os.system(\"terraform init\")\n",
    "    os.system(\"terraform apply --auto-approve\")\n",
    "    print(\"Ec2 instance created\\nVolume created\\n 5 GB Volume attached to instance\")\n",
    " \n",
    " #Bolt:IoT \n",
    "def buzzer():\n",
    "    API_KEY = 'b47XXXXXXXXXXX'\n",
    "    DEVICE_ID = 'BOLTXXXXXXXX'\n",
    "    \n",
    "    mybolt = Bolt(API_KEY, DEVICE_ID)\n",
    "    \n",
    "    buzzer_response = mybolt.digitalWrite(0,'HIGH')\n",
    "    time.sleep(5)\n",
    "    buzzer_response = mybolt.digitalWrite(0,'LOW')\n",
    "    \n",
    "    \n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = model.predict(face)\n",
    "        # harry_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            \n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        \n",
    "        if confidence > 90:\n",
    "            cv2.putText(image, \"Hey Mahek\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "           \n",
    "            \"\"\"\n",
    "            calling of sms ,whatsapp,telegram and mail function which will send email,whatsap messaage,\n",
    "            telegram message and sms with proper date and time\n",
    "            \n",
    "            \"\"\"\"          \n",
    "            sms()\n",
    "            mail()\n",
    "            telegram()\n",
    "            whatsapp()\n",
    "            \n",
    "            break\n",
    "         \n",
    "        else:\n",
    "            cv2.putText(image, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "          \n",
    "            #calling of aws and buzzer function\n",
    "            #A buzzer sound gets produced and instance launched on aws cloud\n",
    "            \n",
    "            aws()\n",
    "            buzzer()\n",
    "            \n",
    "            break\n",
    "    \n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "    \n",
    "   \n",
    "    \n",
    "    if cv2.waitKey(10) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Face Recognition – Unlock Your Computer With Your Face.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
